{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use upsampling and fast neural style techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "matplotlib.rc('figure', figsize=(12, 12))\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, transform):\n",
    "        super(SimpleImageDataset, self).__init__()\n",
    "        \n",
    "        self.image_fnames = [os.path.join(img_dir, f) for f in os.listdir(img_dir)]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.image_fnames[index]).convert('RGB')\n",
    "        return self.transform(img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudnn.benchmark = True\n",
    "image_size = 64\n",
    "batch_size = 32\n",
    "z_dim = 100\n",
    "train_dir_name = '/home/samir/Downloads/ILSVRC2012_img_train/train'\n",
    "test_dir_name = '/home/samir/Downloads/ILSVRC2012_img_train/valid'\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Scale(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#     transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Scale(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#     transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "\n",
    "train_dataset = SimpleImageDataset(train_dir_name, train_transform)\n",
    "test_dataset = SimpleImageDataset(test_dir_name, test_transform)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=7,\n",
    "    pin_memory=True)\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_D(nn.Module):\n",
    "    def __init__(self, img_size):\n",
    "        super(DCGAN_D, self).__init__()\n",
    "        \n",
    "        channel_size = img_size / 2\n",
    "        n_filters = 64\n",
    "        \n",
    "        model = nn.Sequential()\n",
    "        model.add_module(\n",
    "            'conv1', nn.Conv2d(3, n_filters, 4, stride=2, padding=1, bias=False))\n",
    "        model.add_module(\n",
    "            'relu1', nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        # extra layers\n",
    "        extra_layers = 0 # add more layers?\n",
    "        for i in range(extra_layers):\n",
    "            model.add_module('extra-layer-%d-conv' % i,\n",
    "                nn.Conv2d(n_filters, n_filters, 3, 1, 1, bias=False))\n",
    "            model.add_module('extra-layer-%d-batchnorm' % i,\n",
    "                nn.BatchNorm2d(n_filters))\n",
    "            model.add_module('extra-layer-%d-relu' % i,\n",
    "                nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        # pyramid\n",
    "        current_n_channels = n_filters\n",
    "        while channel_size > 4:\n",
    "            \n",
    "            in_c = current_n_channels\n",
    "            out_c = current_n_channels * 2\n",
    "            \n",
    "            model.add_module('pyramid-%d-%d-conv' % (in_c, out_c),\n",
    "                nn.Conv2d(in_c, out_c, 4, 2, 1, bias=False))\n",
    "            model.add_module('pyramid-%d-batchnorm' % out_c,\n",
    "                nn.BatchNorm2d(out_c))\n",
    "            model.add_module('pyramid-%d-relu' % out_c,\n",
    "                nn.LeakyReLU(0.2, inplace=True))\n",
    "            \n",
    "            current_n_channels *= 2\n",
    "            channel_size /= 2\n",
    "        \n",
    "        # final layer outputs a single value\n",
    "        model.add_module('final-%d-1' % current_n_channels,\n",
    "            nn.Conv2d(current_n_channels, 1, 4, 1, bias=False))\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        out = out.mean(0)\n",
    "        return out.view(1)\n",
    "\n",
    "\n",
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self, img_size, z_dim):\n",
    "        super(DCGAN_G, self).__init__()\n",
    "        \n",
    "        n_filters = 32\n",
    "        s = 4\n",
    "        while s != img_size:\n",
    "            n_filters *= 2\n",
    "            s *= 2\n",
    "        \n",
    "        model = nn.Sequential()\n",
    "        model.add_module('deconv1',\n",
    "            nn.ConvTranspose2d(z_dim, n_filters, 4, stride=1, bias=False))\n",
    "        model.add_module('batchnorm1', nn.BatchNorm2d(n_filters))\n",
    "        model.add_module('relu1', nn.ReLU(inplace=True))\n",
    "        \n",
    "        # pyramid\n",
    "        channel_size = 4\n",
    "        while channel_size < img_size // 2:\n",
    "            \n",
    "            in_c = n_filters\n",
    "            out_c = n_filters // 2\n",
    "            \n",
    "            model.add_module('pyramid-%d-%d-deconv' % (in_c, out_c),\n",
    "                nn.ConvTranspose2d(in_c, out_c, 4, 2, 1, bias=False))\n",
    "            model.add_module('pyramid-%d-batchnorm' % out_c,\n",
    "                nn.BatchNorm2d(out_c))\n",
    "            model.add_module('pyramid-%d-relu' % out_c,\n",
    "                nn.ReLU(inplace=True))\n",
    "            \n",
    "            n_filters = n_filters // 2\n",
    "            channel_size *= 2\n",
    "        \n",
    "        # extra layers\n",
    "        extra_layers = 0\n",
    "        for i in range(extra_layers):\n",
    "            model.add_module('extra-layer-%d-conv' % i,\n",
    "                nn.Conv2d(n_filters, n_filters, 3, 1, 1, bias=False))\n",
    "            model.add_module('extra-layer-%d-batchnorm' % i,\n",
    "                nn.BatchNorm2d(n_filters))\n",
    "            model.add_module('extra-layer-%d-relu' % i,\n",
    "                nn.ReLU(inplace=True))\n",
    "        \n",
    "        # final layer outputs a generated image\n",
    "        model.add_module('final-deconv',\n",
    "            nn.ConvTranspose2d(n_filters, 3, 4, 2, 1, bias=False))\n",
    "        model.add_module('final-tanh', nn.Tanh())\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = DCGAN_G(image_size, z_dim).cuda()\n",
    "netD = DCGAN_D(image_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        model.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "\n",
    "netG.apply(weights_init), netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create memory placeholders (manual pinned memory)\n",
    "input_batch = torch.FloatTensor(batch_size, 3, image_size, image_size).cuda()\n",
    "noise_batch = torch.FloatTensor(batch_size, z_dim, 1, 1).cuda()\n",
    "fixed_noise_batch = torch.FloatTensor(batch_size, z_dim, 1, 1).normal_(0,1).cuda()\n",
    "one = torch.FloatTensor([1]).cuda()\n",
    "minus_one = -1 * one\n",
    "\n",
    "# optimiserD = Adam(netD.parameters(), lr=5e-5, betas=(0.5, 0.999))\n",
    "optimiserD = RMSprop(netD.parameters(), lr=5e-5)\n",
    "\n",
    "# optimiserG = Adam(netG.parameters(), lr=5e-5, betas=(0.5, 0.999))\n",
    "optimiserG = RMSprop(netG.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'new-run-experiment'\n",
    "epochs = 25\n",
    "G_iterations = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    data_generator = iter(train_data_loader)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(train_data_loader):\n",
    "        \n",
    "        ###\n",
    "        # train discriminator (D)\n",
    "        ###\n",
    "        \n",
    "        # set discrimnator to trainable\n",
    "        for param in netD.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # if starting or every now and then, increase D's iterations\n",
    "        D_iterations = 5\n",
    "        if G_iterations < 25 or G_iterations % 500 == 0:\n",
    "            D_iterations = 100\n",
    "        \n",
    "        j = 0\n",
    "        while j < D_iterations and i < len(train_data_loader):\n",
    "            j += 1\n",
    "            \n",
    "            # clamp parameters\n",
    "            for param in netD.parameters():\n",
    "                param.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "            # load next batch of real data\n",
    "            real_batch = next(data_generator)\n",
    "            i += 1\n",
    "            \n",
    "            batch_size = real_batch.size(0)\n",
    "            real_batch = real_batch.cuda()\n",
    "            input_batch.resize_as_(real_batch).copy_(real_batch)\n",
    "            input_batch_var = Variable(input_batch)\n",
    "            \n",
    "            # use D to output error of predicting real\n",
    "            netD.zero_grad()\n",
    "            D_real_error = netD(input_batch_var)\n",
    "            D_real_error.backward(one)\n",
    "            \n",
    "            # sample a batch of fake data from a noisy normal distribution\n",
    "            noise_batch.resize_(batch_size, z_dim, 1, 1).normal_(0,1) # shouldnt this be fixed?\n",
    "            noise_var = Variable(noise_batch, volatile=True)\n",
    "            \n",
    "            # use noise as input to generator to generate images\n",
    "            fake_batch = Variable(netG(noise_var).data)\n",
    "            input_batch_var = fake_batch\n",
    "            \n",
    "            # use D to output error of predicting fake\n",
    "            D_fake_error = netD(input_batch_var)\n",
    "            D_fake_error.backward(minus_one)\n",
    "            \n",
    "            # optimise D\n",
    "            D_error = D_real_error - D_fake_error\n",
    "            optimiserD.step()\n",
    "            \n",
    "        ###\n",
    "        # train generator (G)\n",
    "        ###\n",
    "        \n",
    "        # stop training discriminator\n",
    "        for param in netD.parameters():\n",
    "            param.required_grad = False\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        \n",
    "        # sample a batch of fake data from a noisy normal distribution\n",
    "        noise_batch.resize_(batch_size, z_dim, 1, 1).normal_(0,1) # shouldnt this be fixed?\n",
    "        noise_var = Variable(noise_batch)\n",
    "        \n",
    "        # use noise as input to generator to generate images\n",
    "        fake_batch = netG(noise_var)\n",
    "        \n",
    "        # use discrimantor's output to train generator\n",
    "        G_error = netD(fake_batch)\n",
    "        G_error.backward(one)\n",
    "        optimiserG.step()\n",
    "        \n",
    "        G_iterations += 1\n",
    "        \n",
    "        ###\n",
    "        # log\n",
    "        ###\n",
    "        \n",
    "        print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, epochs, i, len(train_data_loader), G_iterations,\n",
    "               D_error.data[0], G_error.data[0],\n",
    "               D_real_error.data[0], D_fake_error.data[0]))\n",
    "        \n",
    "        if G_iterations % 500 == 0:\n",
    "            \n",
    "            # save some real images\n",
    "            real_batch = real_batch.mul(0.5).add(0.5)\n",
    "            vutils.save_image(real_batch, '{}/real_samples.png'.format(experiment_name))\n",
    "            \n",
    "            # save some generated images\n",
    "            fake_batch = netG(Variable(fixed_noise_batch, volatile=True))\n",
    "            fake_batch.data = fake_batch.data.mul(0.5).add(0.5)\n",
    "            vutils.save_image(\n",
    "                fake_batch.data,\n",
    "                '{}/fake_samples_{}.png'.format(experiment_name, G_iterations))\n",
    "    \n",
    "    # save models\n",
    "    torch.save(netG.state_dict(),\n",
    "               '{0}/netG_epoch_{1}.pth'.format(experiment_name, epoch))\n",
    "    torch.save(netD.state_dict(),\n",
    "               '{0}/netD_epoch_{1}.pth'.format(experiment_name, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
